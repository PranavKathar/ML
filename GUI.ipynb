{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da77016e",
      "metadata": {
        "id": "da77016e"
      },
      "outputs": [],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb801ade",
      "metadata": {
        "id": "eb801ade",
        "outputId": "dfcc4c07-776f-4dd3-acd1-f6017d6eafb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "  Downloading torchvision-0.13.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\91726\\anaconda3\\lib\\site-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch==1.12.1 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from torchvision) (1.12.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\91726\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\91726\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91726\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.13.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fa86bba",
      "metadata": {
        "id": "2fa86bba",
        "outputId": "364e70e3-71ff-46d1-f647-51d5b64403a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
            "     ---------------------------------------- 35.6/35.6 MB 8.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.6.0.66\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5da326b",
      "metadata": {
        "id": "d5da326b"
      },
      "outputs": [],
      "source": [
        "#  TCGA dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import models, datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import WeightedRandomSampler, DataLoader, SubsetRandomSampler, Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "# from torchsummary import summary\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "# %matplotlib inline\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c43ef6",
      "metadata": {
        "id": "c8c43ef6",
        "outputId": "de92a127-5636-4ac9-db59-b72087713397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "input_size = 64\n",
        "num_epochs = 47\n",
        "learning_rate = 0.001\n",
        "warm_restart = 12\n",
        "weight_decay = 0.00001\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b8cbe9",
      "metadata": {
        "id": "38b8cbe9"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.fc0 = nn.Linear(input_dim, input_dim//4)\n",
        "        self.fc1 = nn.Linear(input_dim//4, input_dim//16)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(input_dim//16)\n",
        "        self.fc2 = nn.Linear(input_dim//16, input_dim//32)\n",
        "        self.fc3 = nn.Linear(input_dim//32, input_dim//128)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(input_dim//128)\n",
        "        self.fc4 = nn.Linear(input_dim//128, input_dim//32)\n",
        "        self.fc5 = nn.Linear(input_dim//32, input_dim//16)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(input_dim//16)\n",
        "        self.fc6 = nn.Linear(input_dim//16, input_dim//4)\n",
        "        self.fc7 = nn.Linear(input_dim//4, input_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "  \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc0(x))\n",
        "        x = self.relu(self.batchnorm1(self.fc1(x)))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.batchnorm2(self.fc3(x)))\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.relu(self.batchnorm3(self.fc5(x)))\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.fc7(x)\n",
        "        return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8028e7b1",
      "metadata": {
        "id": "8028e7b1"
      },
      "outputs": [],
      "source": [
        "model = Model(input_size*input_size, input_size*input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b447f26",
      "metadata": {
        "id": "0b447f26",
        "outputId": "0e306527-483d-425e-de9e-8dab3f40f3c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc0): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (batchnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (batchnorm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc4): Linear(in_features=32, out_features=128, bias=True)\n",
              "  (fc5): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (batchnorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc6): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (fc7): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5727cabf",
      "metadata": {
        "id": "5727cabf",
        "outputId": "2858ddd1-73b8-4013-c8cd-9b335f0765a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive C is OS\n",
            " Volume Serial Number is 72B3-5164\n",
            "\n",
            " Directory of C:\\Users\\Asus\\Documents\n",
            "\n",
            "17/09/2022  11:50 AM    <DIR>          .\n",
            "17/09/2022  11:50 AM    <DIR>          ..\n",
            "17/09/2022  11:23 AM    <DIR>          .ipynb_checkpoints\n",
            "17/09/2022  11:25 AM    <DIR>          .spyproject\n",
            "17/09/2022  11:50 AM        26,778,802 ML mini projedct.ipynb\n",
            "17/09/2022  11:27 AM             2,329 ML mini projedct.py\n",
            "17/09/2022  11:09 AM        35,991,944 model5.pth\n",
            "17/09/2022  11:36 AM        35,991,944 model7.pth\n",
            "29/06/2020  05:53 PM            46,255 passport_size_photo.jpg\n",
            "23/05/2021  04:37 PM           184,365 There is No.mp3\n",
            "23/05/2021  05:31 PM           184,365 ThereisNo.mp3\n",
            "23/05/2021  05:51 PM            14,934 Untitled.ipynb\n",
            "               8 File(s)     99,194,938 bytes\n",
            "               4 Dir(s)  95,608,389,632 bytes free\n"
          ]
        }
      ],
      "source": [
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ecb61c",
      "metadata": {
        "id": "21ecb61c",
        "outputId": "5cc0f5c9-8928-4f1a-f356-0abc63822102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"model7.pth\"\n",
        "# â€ªmodel.load_state_dict(model_path)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8031dc3",
      "metadata": {
        "id": "c8031dc3",
        "outputId": "9d548aaf-d38c-40be-a186-8d6e994409ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8994656, 8994656)\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(Model): \n",
        "  return sum(p.numel() for p in Model.parameters() if p.requires_grad), sum(p.numel() for p in Model.parameters())\n",
        "print(count_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7820b82f",
      "metadata": {
        "id": "7820b82f",
        "outputId": "08affd8d-8659-4d9d-f64b-811c3e4ab225"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MSELoss()"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion = nn.MSELoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "schedular = CosineAnnealingWarmRestarts(optimizer,warm_restart)\n",
        "criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdac1111",
      "metadata": {
        "id": "cdac1111"
      },
      "outputs": [],
      "source": [
        "def get_sobel(inputs):\n",
        "  sobel = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
        "  sobel_kernel = torch.tensor(sobel, dtype=torch.float32).expand(inputs.size()[1], inputs.size()[1], 3, 3).to(device)\n",
        "  return(sobel_kernel)\n",
        "def get_previt(inputs):\n",
        "  previt = [[1, 1, 1], [0, 0, 0], [-1, -1, -1]]\n",
        "  previt_kernel = torch.tensor(previt, dtype=torch.float32).expand(inputs.size()[1], inputs.size()[1], 3, 3).to(device)\n",
        "  return(previt_kernel)\n",
        "def get_laplacian(inputs):\n",
        "  laplacian = [[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]\n",
        "  laplacian_kernel = torch.tensor(laplacian, dtype=torch.float32).expand(inputs.size()[1], inputs.size()[1], 3, 3).to(device)\n",
        "  return(laplacian_kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2dbcf17",
      "metadata": {
        "scrolled": true,
        "id": "a2dbcf17",
        "outputId": "19dcf21e-2fe6-46e5-d293-9cf20b101805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = Image.open(r\"D:\\College subjects\\7th sem\\Machine Learning\\furniture_images\\furniture_images\\1634011563649_New Office Cupboard 4 X 3 for sale.jpg\")\n",
        "convert_tensor = transforms.ToTensor()\n",
        "convert_tensor(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05293910",
      "metadata": {
        "id": "05293910"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc01916",
      "metadata": {
        "id": "afc01916"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from PIL import ImageTk, Image\n",
        "from tkinter import filedialog\n",
        "from tkinter.filedialog import askopenfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def upload_file():\n",
        "    global img\n",
        "    global w1\n",
        "    f_types = [('Jpg Files', '*.jpg')]\n",
        "    filename = filedialog.askopenfilename(filetypes=f_types)\n",
        "    img = ImageTk.PhotoImage(file=filename)\n",
        "    canvas.create_image(200, 200, anchor=tk.NW, image=img)\n",
        "    w1['state'] = 'normal'\n",
        "\n",
        "def edge_detect():\n",
        "    global img1\n",
        "    # code for processing\n",
        "    img = cv2.imread('download.jpg')\n",
        "    #canny\n",
        "    img_canny = cv2.Canny(img,100,200)\n",
        "    \n",
        "    filename = 'savedImage.jpg'\n",
        "    cv2.imwrite(filename, img_canny)\n",
        "    \n",
        "#     img = ImageTk.PhotoImage(file=filename)\n",
        "    img = ImageTk.PhotoImage(file=\"savedImage.jpg\")\n",
        "\n",
        "    canvas.create_image(1000, 380, anchor=tk.SE, image=img) #need to check\n",
        "    \n",
        "# def prewitt():\n",
        "#     global img2\n",
        "#     # code for processing\n",
        "\n",
        "#     img = cv2.imread('download.jpg')\n",
        "#     if(img is not None):\n",
        "#         gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     img_gaussian = cv2.GaussianBlur(gray,(3,3),0)\n",
        "\n",
        "#     #canny\n",
        "#     img_canny = cv2.Canny(img,100,200)\n",
        "\n",
        "#     img2 = img_canny\n",
        "#     canvas.create_image(1000, 380, anchor=tk.SE, image=img1) #need to check\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "top = tk.Tk()\n",
        "top.title('ML Mini Project')\n",
        "# Create label\n",
        "l = tk.Label(top, text = \"Edge Detector\")\n",
        "l.config(font =(\"Courier\", 14))\n",
        "l.pack()\n",
        "# arranging application parameters\n",
        "canvas = tk.Canvas(top, width=1200,height=550)\n",
        "\n",
        "canvas.pack()\n",
        "\n",
        "w=tk.Button(top, text='Upload Image', width=25, command = upload_file)\n",
        "w.pack()\n",
        "w1=tk.Button(top, text='Edge Map', width=25, command = edge_detect, state=\"disabled\")\n",
        "w1.pack()\n",
        "w_quit=tk.Button(top, text='Exit', width=25, command = top.quit)\n",
        "\n",
        "w_quit.pack()\n",
        "\n",
        "\n",
        "# Code to add widgets will go here...\n",
        "top.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d0b7d5",
      "metadata": {
        "id": "e7d0b7d5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}